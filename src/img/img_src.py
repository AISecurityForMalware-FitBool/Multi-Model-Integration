# -*- coding: utf-8 -*-
#
# PE íŒŒì¼ ë‹¨ì¼ ì¶”ë¡  (Inference) ì›Œí¬í”Œë¡œìš° (Colab/ë¡œì»¬ í˜¸í™˜)
# - PE íŒŒì¼ê³¼ ëª¨ë¸ íŒŒì¼ì„ ê°ê° Colab ì—…ë¡œë“œ ë˜ëŠ” ë¡œì»¬ ì½˜ì†” ì…ë ¥ì„ í†µí•´ ì§€ì •í•©ë‹ˆë‹¤.

import os
import math
import numpy as np
import tensorflow as tf
import cv2
import json # ğŸ’¡ JSON ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
from pathlib import Path
from typing import Dict, Any

# --- Colab íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œë„ ---
try:
    from google.colab import files
    IS_COLAB = True
except ImportError:
    files = None
    IS_COLAB = False
# ----------------------------------------

# =========================================================================
# ğŸš¨ ì‚¬ìš©ì ì§€ì • í•„ìˆ˜ ê²½ë¡œ ì„¤ì • (ê¸°ë³¸ê°’ ì„¤ì • ë° í´ë” ìƒì„±)
# =========================================================================

# 1. ë¡œì»¬ ì‘ì—… ê³µê°„ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ìœ„ì¹˜ ê¸°ì¤€)
LOCAL_ASSET_ROOT = "./PE_Inference_Assets"
os.makedirs(LOCAL_ASSET_ROOT, exist_ok=True)

# 2. ëª¨ë¸ í´ë” ê²½ë¡œ ë° ê¸°ë³¸ ëª¨ë¸ íŒŒì¼ ì´ë¦„ (ì—…ë¡œë“œ í›„ ì €ì¥ë  ì„ì‹œ í´ë”)
MODEL_DIR = os.path.join(LOCAL_ASSET_ROOT, "model")
os.makedirs(MODEL_DIR, exist_ok=True)

# 3. ë¶„ì„ëœ ì´ë¯¸ì§€ ë° ê²°ê³¼ ì €ì¥ ê²½ë¡œ
# ğŸ’¡ ê²½ë¡œë¥¼ ./srcë¡œ ì§ì ‘ ìˆ˜ì •
INFERENCE_IMG_SAVE_DIR = "./src"
os.makedirs(INFERENCE_IMG_SAVE_DIR, exist_ok=True)
 
# ğŸ’¡ JSON ê²°ê³¼ ì €ì¥ ê²½ë¡œë„ ./srcë¡œ ì§ì ‘ ìˆ˜ì •
INFERENCE_JSON_SAVE_DIR = "./src" # ì´ë¯¸ì§€ì™€ ê°™ì€ í´ë”ì— ì €ì¥
os.makedirs(INFERENCE_JSON_SAVE_DIR, exist_ok=True)

# =========================================================================
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ìœ í‹¸ë¦¬í‹° (ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
# =========================================================================

IMG_SIZE = 300
CLASS_NAMES = ["Normal", "Malware"] # 0: Normal, 1: Malware
from tensorflow.keras.applications import efficientnet_v2
preprocess_input = efficientnet_v2.preprocess_input

# [ì›ë³¸ ì „ì²˜ë¦¬ ì½”ë“œì—ì„œ ê°€ì ¸ì˜¨ í•¨ìˆ˜: 1. width_by_size]
def width_by_size(n_bytes: int) -> int:
    """ë°”ì´íŠ¸ í¬ê¸°ì— ë”°ë¼ ì´ë¯¸ì§€ì˜ ë„ˆë¹„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    if n_bytes < 10*1024: return 32
    if n_bytes < 30*1024: return 64
    if n_bytes < 60*1024: return 128
    if n_bytes < 100*1024: return 256
    if n_bytes < 200*1024: return 384
    if n_bytes < 500*1024: return 512
    if n_bytes < 1024*1024: return 768
    return 1024

# [ì›ë³¸ ì „ì²˜ë¦¬ ì½”ë“œì—ì„œ ê°€ì ¸ì˜¨ í•¨ìˆ˜: 2. exe_bytes_to_gray_square]
def exe_bytes_to_gray_square(bytes_data: bytes, target=IMG_SIZE):
    """PE ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ GrayScale ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ (300x300)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    N = len(bytes_data)
    W = width_by_size(N)
    H = math.ceil(N / W)
    arr = np.frombuffer(bytes_data, dtype=np.uint8)

    # 0ìœ¼ë¡œ íŒ¨ë”© (H*W í¬ê¸°ë¡œ ë§ì¶¤)
    if len(arr) < H*W:
        arr = np.pad(arr, (0, H*W - len(arr)), constant_values=0)

    img = arr.reshape(H, W)

    # ì •ì‚¬ê°í˜•ìœ¼ë¡œ í™•ì¥ í›„ ë¦¬ì‚¬ì´ì¦ˆ (cv2.INTER_AREA ì‚¬ìš©)
    side = max(H, W)
    sq = np.zeros((side, side), dtype=np.uint8)
    sq[:H, :W] = img
    sq = cv2.resize(sq, (target, target), interpolation=cv2.INTER_AREA)
    return sq

# =========================================================================
# ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜ (JSON ì €ì¥ ë¡œì§ ë° í˜•ì‹ í†µì¼)
# =========================================================================

def inference_pipeline(pe_path: str, model_path: str) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì…ë ¥ ê²½ë¡œë¥¼ ë°›ì•„ ëª¨ë¸ ë¡œë“œ ë° PE íŒŒì¼ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    print(f"ğŸš€ PE íŒŒì¼ ë¶„ì„ ì‹œì‘: {pe_path}")

    if not os.path.exists(pe_path):
        print(f"[ERROR] PE íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pe_path}")
        return {"error": "PE file not found"}

    # 1. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
    if not os.path.exists(model_path):
        print(f"[ERROR] í•™ìŠµëœ ìµœì¢… ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return {"error": "Model file not found"}

    print("âœ… ìµœì¢… ëª¨ë¸ ë¡œë“œ ì¤‘...")
    try:
        model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

    # 2. PE íŒŒì¼ ì „ì²˜ë¦¬ ë° ì´ë¯¸ì§€í™”
    print("âœ… PE íŒŒì¼ ì „ì²˜ë¦¬ (ë°”ì´íŠ¸ -> GrayScale ì´ë¯¸ì§€ 300x300) ì¤‘...")
    try:
        with open(pe_path, "rb") as f:
            data_bytes = f.read()

        # 2-1. GrayScale ì´ë¯¸ì§€ ë³€í™˜ (ì›ë³¸ ì „ì²˜ë¦¬ ë¡œì§)
        gray_img_np = exe_bytes_to_gray_square(data_bytes, target=IMG_SIZE)

        # 2-2. 3ì±„ë„(RGB)ë¡œ í™•ì¥
        input_image_raw = np.stack([gray_img_np]*3, axis=-1).astype(np.float32)

        # 2-3. EfficientNetV2 í‘œì¤€ ì „ì²˜ë¦¬ ì ìš©
        input_image_processed = preprocess_input(input_image_raw)

        # 2-4. ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        input_tensor = np.expand_dims(input_image_processed, axis=0)

    except Exception as e:
        print(f"[ERROR] ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

    # 3. ì˜ˆì¸¡ ìˆ˜í–‰
    print("âœ… ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    prediction_proba = model.predict(input_tensor, verbose=0)[0][0]

    # 4. ê²°ê³¼ íŒë³„ ë° í™•ë¥  ê³„ì‚°
    threshold = 0.5
    predicted_class = 1 if prediction_proba >= threshold else 0

    malware_prob_percent = prediction_proba * 100
    normal_prob_percent = (1.0 - prediction_proba) * 100

    file_name = Path(pe_path).stem + "_" + Path(pe_path).suffix.replace(".", "")

    # 5. ì´ë¯¸ì§€ ì €ì¥ (GrayScale PNG)
    output_img_path = os.path.join(INFERENCE_IMG_SAVE_DIR, f"{file_name}_gray_{IMG_SIZE}x{IMG_SIZE}.png")

    try:
        cv2.imwrite(output_img_path, gray_img_np)
        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_img_path}")
    except Exception as e:
        print(f"[ERROR] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

    # 6. ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (ğŸ’¡ Prediction ë¸”ë¡ì„ PE Feature ëª¨ë¸ í˜•ì‹ì— ë§ê²Œ ìˆ˜ì •)
    result_dict = {
        "input_path": pe_path,
        "prediction": {
            "prob": float(prediction_proba),             # ì•…ì„±(Malware) í™•ë¥  (0~1)
            "prob_percent": float(malware_prob_percent), # ì•…ì„±(Malware) í™•ë¥  (í¼ì„¼íŠ¸)
            "label": predicted_class                     # ì˜ˆì¸¡ ì¸ë±ìŠ¤ (0: Normal, 1: Malware)
        },
        "details": {
            # PE Feature ëª¨ë¸ì—ëŠ” ì—†ëŠ” ì •ë³´ì´ì§€ë§Œ, ì´ë¯¸ì§€ ëª¨ë¸ì—ë§Œ ìœ íš¨í•œ ìƒì„¸ ì •ë³´ëŠ” detailsì— ìœ ì§€
            "image_path": output_img_path,
            "model_path": model_path
        }
    }

    # 7. ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì•…ì„±/ì •ìƒ íŒë³„ ë° í™•ë¥ ) - ì¶œë ¥ ë©”ì‹œì§€ëŠ” ê°€ë…ì„±ì„ ìœ„í•´ ìœ ì§€
    print(f"\n{'='*15} ğŸ”® ë¶„ì„ ê²°ê³¼ {'='*15}")
    print(f"PE íŒŒì¼ëª…: {Path(pe_path).name}")
    print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤: {CLASS_NAMES[predicted_class]}")
    print(f"ì•…ì„±(Malware) í™•ë¥ : **{malware_prob_percent:.2f}%**")
    print(f"ì •ìƒ(Normal) í™•ë¥ : **{normal_prob_percent:.2f}%**")
    print(f"ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {output_img_path}")
    print(f"{'='*36}\n")

    # 8. ğŸ’¡ JSON íŒŒì¼ ì €ì¥ (ì¶”ê°€ëœ í•µì‹¬ ê¸°ëŠ¥)
    json_filename = f"{file_name}_image_result.json"
    output_json_path = os.path.join(INFERENCE_JSON_SAVE_DIR, json_filename)

    try:
        with open(output_json_path, 'w', encoding='utf-8') as f:
            # indent=4ë¥¼ ì‚¬ìš©í•˜ì—¬ JSONì„ ë³´ê¸° ì¢‹ê²Œ ì €ì¥í•©ë‹ˆë‹¤.
            json.dump(result_dict, f, ensure_ascii=False, indent=4)
        print(f"âœ… JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_json_path}")
        result_dict['json_path'] = output_json_path
    except Exception as e:
        print(f"[ERROR] JSON ì €ì¥ ì‹¤íŒ¨: {e}")

    return result_dict


def get_user_input_paths():
    """í™˜ê²½ì— ë”°ë¼ PE íŒŒì¼ê³¼ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ëŠ” í•¨ìˆ˜."""
    print("="*50)
    print(" PE íŒŒì¼ ë° ëª¨ë¸ ê²½ë¡œ ì§€ì •")
    print("="*50)

    pe_path = ""
    model_path = ""

    # 1. PE íŒŒì¼ ê²½ë¡œ ì…ë ¥
    if IS_COLAB:
        print("1. ë¶„ì„í•  PE íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (Colab 'Choose Files' ë²„íŠ¼ ì‚¬ìš©):")
        uploaded = files.upload()
        if uploaded:
            pe_path = os.path.join("/content", list(uploaded.keys())[0])
        else:
            print("[WARN] PE íŒŒì¼ ì—…ë¡œë“œ ì·¨ì†Œ.")
            return "", ""
    else:
        pe_path = input("1. ë¶„ì„í•  PE íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: C:/malware/sample.exe): ").strip()

    # 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì…ë ¥
    print("\n2. ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼(final_model_all_data.keras) ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.")

    if IS_COLAB:
        print("ëª¨ë¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (Colab 'Choose Files' ë²„íŠ¼ ì‚¬ìš©):")
        uploaded_model = files.upload()
        if uploaded_model:
            model_path = os.path.join("/content", list(uploaded_model.keys())[0])
        else:
            print("[WARN] ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ ì·¨ì†Œ.")
            return pe_path, ""
    else:
        model_path = input("ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ./PE_Inference_Assets/model/final.keras): ").strip()

    print(f"\n-> PE íŒŒì¼ ê²½ë¡œ: {pe_path}")
    print(f"-> ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {model_path}")

    return pe_path, model_path


if __name__ == "__main__":

    # ì‚¬ìš©ìë¡œë¶€í„° PE íŒŒì¼ ê²½ë¡œ ë° ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ìŒ
    user_pe_path, final_model_path = get_user_input_paths()

    # ìœ íš¨ì„± ê²€ì‚¬ ë° ë¶„ì„ ì‹¤í–‰
    if user_pe_path and final_model_path:
        # ğŸ’¡ ì¶”ë¡  ê²°ê³¼ë¥¼ ë°›ì•„ì„œ (ì„ íƒ ì‚¬í•­) ì¶”ê°€ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        result = inference_pipeline(user_pe_path, final_model_path)

        # ğŸ’¡ JSON íŒŒì¼ ì €ì¥ í™•ì¸ ë©”ì‹œì§€
        if "json_path" in result:
            print(f"\nğŸ“¢ ë³´íŒ… ìŠ¤í¬ë¦½íŠ¸ê°€ ì‚¬ìš©í•  ì´ë¯¸ì§€ ëª¨ë¸ ê²°ê³¼: {result['json_path']}")

    else:
        print("[ERROR] ìœ íš¨í•œ PE íŒŒì¼ ê²½ë¡œì™€ ëª¨ë¸ íŒŒì¼ ê²½ë¡œê°€ ëª¨ë‘ ì§€ì •ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")